{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5443e8e8",
   "metadata": {},
   "source": [
    "# üèéÔ∏è Model 1: Random Forest - Multi-Target Prediction\n",
    "\n",
    "**Goal:** Predict multiple F1 race outcomes using Random Forest\n",
    "\n",
    "**Targets:**\n",
    "- üèÜ **Classification**: win, podium, points_finish, top5 (binary 0/1)\n",
    "- üìä **Regression**: position (1-20)\n",
    "\n",
    "**Process:**\n",
    "1. Train baseline models (Classifier + Regressor)\n",
    "2. Hyperparameter optimization for both\n",
    "3. Compare baseline vs optimized\n",
    "4. Evaluate and visualize all targets\n",
    "5. Save best models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27525436",
   "metadata": {},
   "source": [
    "## Step 1 : Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81cb0dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import joblib\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    accuracy_score,\n",
    "    r2_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    make_scorer\n",
    ")\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b8f204",
   "metadata": {},
   "source": [
    "## Step 2 : Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "542cf7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data\n",
      "\n",
      " Data loaded successfully!\n",
      "   Training samples: 460 (2024 season)\n",
      "   Test samples: 385 (2025 season)\n",
      "   Features: 72\n",
      "   Target columns: ['win', 'podium', 'points_finish', 'top5', 'position']\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading processed data\")\n",
    "\n",
    "train_df = pd.read_parquet('../data/processed/train_data_v2.parquet')\n",
    "test_df = pd.read_parquet('../data/processed/test_data_v2.parquet')\n",
    "\n",
    "train_weights = np.load('../data/processed/train_weights.npy')\n",
    "test_weights = np.load('../data/processed/test_weights.npy')\n",
    "\n",
    "with open('../data/processed/metadata_v2.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(f\"\\n Data loaded successfully!\")\n",
    "print(f\"   Training samples: {len(train_df)} (2024 season)\")\n",
    "print(f\"   Test samples: {len(test_df)} (2025 season)\")\n",
    "print(f\"   Features: {len(metadata['feature_columns'])}\")\n",
    "print(f\"   Target columns: {metadata['target_columns']}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6e700d",
   "metadata": {},
   "source": [
    "## Step 3 : Preparing Features and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e063e09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data prepared for training:\n",
      "   Features shape: (460, 72)\n",
      "   Classification targets: ['win', 'podium', 'points_finish', 'top5']\n",
      "   Regression target: position\n",
      "\n",
      " Target Distribution (Training):\n",
      "   win: 5.2% positive\n",
      "   podium: 15.7% positive\n",
      "   points_finish: 50.9% positive\n",
      "   top5: 26.1% positive\n",
      "   position: mean=10.38, std=5.81\n"
     ]
    }
   ],
   "source": [
    "feature_cols = metadata['feature_columns']\n",
    "\n",
    "classification_targets = ['win','podium','points_finish','top5']\n",
    "regression_target = 'position'\n",
    "all_targets = classification_targets + [regression_target]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "X_test = test_df[feature_cols]\n",
    "\n",
    "y_train_class = train_df[classification_targets]\n",
    "y_test_class = test_df[classification_targets]\n",
    "\n",
    "y_train_reg = train_df[regression_target]\n",
    "y_test_reg = train_df[regression_target]\n",
    "\n",
    "print(f\"\\n Data prepared for training:\")\n",
    "print(f\"   Features shape: {X_train.shape}\")\n",
    "print(f\"   Classification targets: {classification_targets}\")\n",
    "print(f\"   Regression target: {regression_target}\")\n",
    "\n",
    "print(f\"\\n Target Distribution (Training):\")\n",
    "for target in classification_targets:\n",
    "    pos_rate = train_df[target].mean() * 100\n",
    "    print(f\"   {target}: {pos_rate:.1f}% positive\")\n",
    "print(f\"   position: mean={y_train_reg.mean():.2f}, std={y_train_reg.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd23759",
   "metadata": {},
   "source": [
    "## Step 4 : Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "460baf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Evaluation functions defined!\n"
     ]
    }
   ],
   "source": [
    "def calculate_classification_metrics(y_true,y_pred,y_prob=None,weights=None,target_name=\"Target\"):\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred, sample_weight = weights)\n",
    "    prec = precision_score(y_true, y_pred, sample_weight = weights)\n",
    "    rec = recall_score(y_true,y_pred,sample_weight = weights)\n",
    "    f1 = f1_score(y_true,y_pred,sample_weight = weights)\n",
    "\n",
    "    auc = roc_auc_score(y_true, y_prob,sample_weight = weights) if y_prob is not None else None\n",
    "\n",
    "    return {\n",
    "        'Accuracy' : acc,\n",
    "        'Precision' : prec,\n",
    "        'Recall' : rec,\n",
    "        'F1' : f1,\n",
    "        'AUC' : auc\n",
    "    }\n",
    "\n",
    "\n",
    "def calculate_regression_metrics(y_true, y_pred,weights=None):\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred, sample_weight = weights)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred, sample_weight=weights))\n",
    "    r2 = r2_score(y_true, y_pred,sample_weight = weights)\n",
    "\n",
    "    within_1 = np.mean(np.abs(y_true - y_pred) <= 1) * 100\n",
    "    within_2 = np.mean(np.abs(y_true - y_pred) <= 2) * 100\n",
    "    within_3 = np.mean(np.abs(y_true - y_pred) <= 3) * 100\n",
    "    \n",
    "    return {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'Within_1': within_1,\n",
    "        'Within_2': within_2,\n",
    "        'Within_3': within_3\n",
    "    }\n",
    "\n",
    "\n",
    "def print_classification_metrics(metrics, dataset_name=\"Dataset\"):\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\" {dataset_name.upper()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"   Accuracy:  {metrics['Accuracy']:.3f} ({metrics['Accuracy']*100:.1f}%)\")\n",
    "    print(f\"   Precision: {metrics['Precision']:.3f}\")\n",
    "    print(f\"   Recall:    {metrics['Recall']:.3f}\")\n",
    "    print(f\"   F1 Score:  {metrics['F1']:.3f}\")\n",
    "    if metrics['AUC'] is not None:\n",
    "        print(f\"   ROC AUC:   {metrics['AUC']:.3f}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "\n",
    "def print_regression_metrics(metrics, dataset_name=\"Dataset\"):\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\" {dataset_name.upper()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"   MAE:  {metrics['MAE']:.3f} positions\")\n",
    "    print(f\"   RMSE: {metrics['RMSE']:.3f} positions\")\n",
    "    print(f\"   R¬≤:   {metrics['R2']:.3f}\")\n",
    "    print(f\"\\nüéØ ACCURACY:\")\n",
    "    print(f\"   Within 1 position:  {metrics['Within_1']:.1f}%\")\n",
    "    print(f\"   Within 2 positions: {metrics['Within_2']:.1f}%\")\n",
    "    print(f\"   Within 3 positions: {metrics['Within_3']:.1f}%\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "print(\" Evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ce0a65",
   "metadata": {},
   "source": [
    "# PART A : CLASSIFICATION MODELS (win,podium,top5,points_finish)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0806ee3",
   "metadata": {},
   "source": [
    "## Step 5 : Baseline classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24b794a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Baseline Classification Parameters:\n",
      "   n_estimators: 100\n",
      "   max_depth: 15\n",
      "   min_samples_split: 10\n",
      "   min_samples_leaf: 4\n",
      "   max_features: sqrt\n",
      "   class_weight: balanced\n",
      "\n",
      "  Training baseline classifier for 'win'...\n",
      "     win: Train Accuracy = 97.4%, F1 = 80.0%, AUC = 99.8%, Precision = 66.7%, Recall = 100.0%\n",
      "     win: Test Accuracy = 94.5%, F1 = 52.3%, AUC = 95.8%, Precision = 47.7%, Recall = 57.9%\n",
      "\n",
      "  Training baseline classifier for 'podium'...\n",
      "     podium: Train Accuracy = 91.4%, F1 = 78.1%, AUC = 98.4%, Precision = 65.7%, Recall = 96.1%\n",
      "     podium: Test Accuracy = 90.9%, F1 = 75.3%, AUC = 95.2%, Precision = 65.4%, Recall = 88.8%\n",
      "\n",
      "  Training baseline classifier for 'points_finish'...\n",
      "     points_finish: Train Accuracy = 91.8%, F1 = 92.0%, AUC = 97.9%, Precision = 91.8%, Recall = 92.2%\n",
      "     points_finish: Test Accuracy = 78.4%, F1 = 79.3%, AUC = 84.7%, Precision = 79.4%, Recall = 79.2%\n",
      "\n",
      "  Training baseline classifier for 'top5'...\n",
      "     top5: Train Accuracy = 93.3%, F1 = 88.3%, AUC = 98.8%, Precision = 81.9%, Recall = 95.9%\n",
      "     top5: Test Accuracy = 87.2%, F1 = 76.2%, AUC = 90.7%, Precision = 74.2%, Recall = 78.2%\n",
      "\n",
      "‚úÖ All baseline classification models trained!\n"
     ]
    }
   ],
   "source": [
    "baseline_class_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 15,\n",
    "    'min_samples_split': 10,\n",
    "    'min_samples_leaf': 4,\n",
    "    'max_features': 'sqrt',\n",
    "    'class_weight': 'balanced',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "print(\"\\n Baseline Classification Parameters:\")\n",
    "for param, value in baseline_class_params.items():\n",
    "    if param not in ['random_state', 'n_jobs']:\n",
    "        print(f\"   {param}: {value}\")\n",
    "\n",
    "baseline_class_models = {}\n",
    "baseline_class_results = {}\n",
    "\n",
    "for target in classification_targets:\n",
    "    print(f\"\\n  Training baseline classifier for '{target}'...\")\n",
    "    \n",
    "    model = RandomForestClassifier(**baseline_class_params)\n",
    "    model.fit(X_train, y_train_class[target], sample_weight=train_weights)\n",
    "    \n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    train_prob = model.predict_proba(X_train)[:, 1]\n",
    "    test_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    train_metrics = calculate_classification_metrics(\n",
    "        y_train_class[target], train_pred, train_prob, train_weights, target\n",
    "    )\n",
    "    test_metrics = calculate_classification_metrics(\n",
    "        y_test_class[target], test_pred, test_prob, test_weights, target\n",
    "    )\n",
    "    \n",
    "    baseline_class_models[target] = model\n",
    "    baseline_class_results[target] = {\n",
    "        'train_metrics': train_metrics,\n",
    "        'test_metrics': test_metrics,\n",
    "        'train_pred': train_pred,\n",
    "        'test_pred': test_pred,\n",
    "        'train_prob': train_prob,\n",
    "        'test_prob': test_prob\n",
    "    }\n",
    "    \n",
    "    print(f\"     {target}: Train Accuracy = {train_metrics['Accuracy']*100:.1f}%, \"\n",
    "          f\"F1 = {train_metrics['F1']*100:.1f}%, AUC = {train_metrics['AUC']*100:.1f}%, \"\n",
    "          f\"Precision = {train_metrics['Precision']*100:.1f}%, Recall = {train_metrics['Recall']*100:.1f}%\")\n",
    "\n",
    "    print(f\"     {target}: Test Accuracy = {test_metrics['Accuracy']*100:.1f}%, \"\n",
    "          f\"F1 = {test_metrics['F1']*100:.1f}%, AUC = {test_metrics['AUC']*100:.1f}%, \"\n",
    "          f\"Precision = {test_metrics['Precision']*100:.1f}%, Recall = {test_metrics['Recall']*100:.1f}%\")\n",
    "\n",
    "print(\"\\n‚úÖ All baseline classification models trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094ec8bb",
   "metadata": {},
   "source": [
    "\n",
    "### **Baseline Classification Results**\n",
    "\n",
    "- This cell trains the four baseline classifiers, which clearly demonstrate **overfitting**.\n",
    "\n",
    "- The models performed perfectly on the 2024 training data (e.g., the `win` model achieved 100% recall and an 80% F1), but their performance dropped significantly on the unseen 2025 test set (the `win` model's F1 fell to 52.3%).\n",
    "\n",
    "- This large gap between training and test scores shows the models \"memorized\" the 2024 season instead of learning general patterns.\n",
    "\n",
    "- The next hyperparameter tuning step is essential to reduce this overfitting and improve real-world performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0388e0e0",
   "metadata": {},
   "source": [
    "## Step 6 : Optimize Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53becf86",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
