{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed81ab1",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e8963f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os,re,json\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c045b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "DATABASE_URL = os.getenv(\"DATABASE_URL\", \"postgresql://postgres:postgres@localhost:5432/f1_db\")\n",
    "\n",
    "engine = create_engine(DATABASE_URL.replace(\"postgresql+asyncpg://\", \"postgresql://\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e96f26",
   "metadata": {},
   "source": [
    "### Loading raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "921d3c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data...\n",
      "✅ Loaded 1699 records with qualifying data\n",
      "   Qualifying data coverage: 1699 / 1699\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoading data...\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    rr.id as result_id, rr.position, rr.grid_position, rr.points, rr.laps_completed, rr.fastest_lap_rank,\n",
    "    rr.status, rr.is_sprint,\n",
    "    d.id as driver_id, d.code as driver_code, d.driver_number, d.nationality as driver_nationality,\n",
    "    EXTRACT(YEAR FROM AGE(r.race_date, d.date_of_birth)) as driver_age,\n",
    "    d.championships as driver_championships,\n",
    "    t.id as team_id, t.name as team_name,\n",
    "    r.id as race_id, r.season, r.round_number, r.race_name, r.circuit_location, r.country,\n",
    "    r.circuit_type, r.laps as total_laps, r.circuit_length, r.has_sprint, r.race_date,\n",
    "    qr.position as quali_position, qr.q1_time, qr.q2_time, qr.q3_time\n",
    "FROM race_results rr\n",
    "JOIN drivers d ON rr.driver_id = d.id\n",
    "JOIN teams t ON rr.team_id = t.id\n",
    "JOIN races r ON rr.race_id = r.id\n",
    "LEFT JOIN qualifying_results qr ON rr.race_id = qr.race_id AND rr.driver_id = qr.driver_id\n",
    "WHERE rr.is_sprint = False\n",
    "ORDER BY r.season, r.round_number, rr.position;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, engine)\n",
    "print(f\"✅ Loaded {len(df)} records with qualifying data\")\n",
    "print(f\"   Qualifying data coverage: {df['quali_position'].notna().sum()} / {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a83b86ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fill complete. Checking for remaining missing values:\n",
      "circuit_type: 0 missing\n",
      "total_laps: 0 missing\n",
      "circuit_length: 0 missing\n",
      "\n",
      "✅ Success! All circuit locations were matched and filled.\n"
     ]
    }
   ],
   "source": [
    "circuit_data_map = {\n",
    "    # 2022-2025 Tracks (with all known aliases)\n",
    "    \"Sakhir\": (\"Permanent\", 57, 5.412),\n",
    "    \"Jeddah\": (\"Street\", 50, 6.174),\n",
    "    \"Melbourne\": (\"Street\", 58, 5.278),\n",
    "    \"Suzuka\": (\"Permanent\", 53, 5.807),\n",
    "    \"Shanghai\": (\"Permanent\", 56, 5.451),\n",
    "    \"Miami Gardens\": (\"Street\", 57, 5.412),   \n",
    "    \"Miami\": (\"Street\", 57, 5.412),          \n",
    "    \"Imola\": (\"Permanent\", 63, 4.909),\n",
    "    \"Monaco\": (\"Street\", 78, 3.337),\n",
    "    \"Montréal\": (\"Street\", 70, 4.361),\n",
    "    \"Barcelona\": (\"Permanent\", 66, 4.657),\n",
    "    \"Spielberg\": (\"Permanent\", 71, 4.318),\n",
    "    \"Silverstone\": (\"Permanent\", 52, 5.891),\n",
    "    \"Budapest\": (\"Permanent\", 70, 4.381),\n",
    "    \"Spa-Francorchamps\": (\"Permanent\", 44, 7.004),\n",
    "    \"Zandvoort\": (\"Permanent\", 72, 4.259),\n",
    "    \"Monza\": (\"Permanent\", 53, 5.793),\n",
    "    \"Baku\": (\"Street\", 51, 6.003),\n",
    "    \"Marina Bay\": (\"Street\", 62, 4.940),\n",
    "    \"Austin\": (\"Permanent\", 56, 5.513),\n",
    "    \"Mexico City\": (\"Permanent\", 71, 4.304),\n",
    "    \"São Paulo\": (\"Permanent\", 71, 4.309),\n",
    "    \"Las Vegas\": (\"Street\", 50, 6.201),\n",
    "    \"Lusail\": (\"Permanent\", 57, 5.419),\n",
    "    \"Yas Island\": (\"Permanent\", 58, 5.281),\n",
    "    \"Le Castellet\": (\"Permanent\", 53, 5.842) # For 2022 French GP\n",
    "}\n",
    "\n",
    "key_column = 'circuit_location' \n",
    "\n",
    "mapped_data = df[key_column].map(circuit_data_map)\n",
    "\n",
    "df['circuit_type'] = df['circuit_type'].fillna(mapped_data.str[0])\n",
    "df['total_laps'] = df['total_laps'].fillna(mapped_data.str[1])\n",
    "df['circuit_length'] = df['circuit_length'].fillna(mapped_data.str[2])\n",
    "\n",
    "print(\"Fill complete. Checking for remaining missing values:\")\n",
    "print(f\"circuit_type: {df['circuit_type'].isna().sum()} missing\")\n",
    "print(f\"total_laps: {df['total_laps'].isna().sum()} missing\")\n",
    "print(f\"circuit_length: {df['circuit_length'].isna().sum()} missing\")\n",
    "\n",
    "# Verification\n",
    "all_db_locations = set(df['circuit_location'].unique())\n",
    "all_map_keys = set(circuit_data_map.keys())\n",
    "mismatched_keys = all_db_locations - all_map_keys\n",
    "\n",
    "if len(mismatched_keys) > 0:\n",
    "    print(f\"\\n⚠️ WARNING: Mismatched keys found!\")\n",
    "    print(f\"   These locations are in your database but NOT in the map:\")\n",
    "    print(f\"   {mismatched_keys}\")\n",
    "else:\n",
    "    print(\"\\n✅ Success! All circuit locations were matched and filled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd42b956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "result_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "position",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "grid_position",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "points",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "laps_completed",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fastest_lap_rank",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "is_sprint",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "driver_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "driver_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "driver_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "driver_nationality",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "driver_age",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "driver_championships",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "team_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "team_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "race_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "season",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "round_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "race_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "circuit_location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "circuit_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "total_laps",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "circuit_length",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "has_sprint",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "race_date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "quali_position",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "q1_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "q2_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "q3_time",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "5a9e4ecd-d8d6-499d-a15e-67f7dfa33f66",
       "rows": [
        [
         "0",
         "1037",
         "1.0",
         "1.0",
         "26.0",
         "57",
         "1.0",
         "Finished",
         "False",
         "4",
         "LEC",
         "16",
         null,
         null,
         "0",
         "2",
         "Ferrari",
         "50",
         "2022",
         "1",
         "Bahrain Grand Prix",
         "Sakhir",
         "Bahrain",
         "Permanent",
         "57",
         "5.412",
         "0",
         "2022-03-20",
         "1",
         "0 days 00:01:31.471000",
         "0 days 00:01:30.932000",
         "0 days 00:01:30.558000"
        ],
        [
         "1",
         "1038",
         "2.0",
         "3.0",
         "18.0",
         "57",
         "3.0",
         "Finished",
         "False",
         "3",
         "SAI",
         "55",
         null,
         null,
         "0",
         "2",
         "Ferrari",
         "50",
         "2022",
         "1",
         "Bahrain Grand Prix",
         "Sakhir",
         "Bahrain",
         "Permanent",
         "57",
         "5.412",
         "0",
         "2022-03-20",
         "3",
         "0 days 00:01:31.567000",
         "0 days 00:01:30.787000",
         "0 days 00:01:30.687000"
        ],
        [
         "2",
         "1039",
         "3.0",
         "5.0",
         "15.0",
         "57",
         "5.0",
         "Finished",
         "False",
         "7",
         "HAM",
         "44",
         null,
         null,
         "0",
         "3",
         "Mercedes",
         "50",
         "2022",
         "1",
         "Bahrain Grand Prix",
         "Sakhir",
         "Bahrain",
         "Permanent",
         "57",
         "5.412",
         "0",
         "2022-03-20",
         "5",
         "0 days 00:01:32.285000",
         "0 days 00:01:31.048000",
         "0 days 00:01:31.238000"
        ],
        [
         "3",
         "1040",
         "4.0",
         "9.0",
         "12.0",
         "57",
         "6.0",
         "Finished",
         "False",
         "5",
         "RUS",
         "63",
         null,
         null,
         "0",
         "3",
         "Mercedes",
         "50",
         "2022",
         "1",
         "Bahrain Grand Prix",
         "Sakhir",
         "Bahrain",
         "Permanent",
         "57",
         "5.412",
         "0",
         "2022-03-20",
         "9",
         "0 days 00:01:32.269000",
         "0 days 00:01:31.252000",
         "0 days 00:01:32.216000"
        ],
        [
         "4",
         "1041",
         "5.0",
         "7.0",
         "10.0",
         "57",
         "8.0",
         "Finished",
         "False",
         "12",
         "MAG",
         "20",
         null,
         null,
         "0",
         "7",
         "Haas F1 Team",
         "50",
         "2022",
         "1",
         "Bahrain Grand Prix",
         "Sakhir",
         "Bahrain",
         "Permanent",
         "57",
         "5.412",
         "0",
         "2022-03-20",
         "7",
         "0 days 00:01:31.955000",
         "0 days 00:01:31.461000",
         "0 days 00:01:31.808000"
        ]
       ],
       "shape": {
        "columns": 31,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result_id</th>\n",
       "      <th>position</th>\n",
       "      <th>grid_position</th>\n",
       "      <th>points</th>\n",
       "      <th>laps_completed</th>\n",
       "      <th>fastest_lap_rank</th>\n",
       "      <th>status</th>\n",
       "      <th>is_sprint</th>\n",
       "      <th>driver_id</th>\n",
       "      <th>driver_code</th>\n",
       "      <th>...</th>\n",
       "      <th>country</th>\n",
       "      <th>circuit_type</th>\n",
       "      <th>total_laps</th>\n",
       "      <th>circuit_length</th>\n",
       "      <th>has_sprint</th>\n",
       "      <th>race_date</th>\n",
       "      <th>quali_position</th>\n",
       "      <th>q1_time</th>\n",
       "      <th>q2_time</th>\n",
       "      <th>q3_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1037</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Finished</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>LEC</td>\n",
       "      <td>...</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>57</td>\n",
       "      <td>5.412</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-20</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days 00:01:31.471000</td>\n",
       "      <td>0 days 00:01:30.932000</td>\n",
       "      <td>0 days 00:01:30.558000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1038</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>57</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Finished</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>SAI</td>\n",
       "      <td>...</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>57</td>\n",
       "      <td>5.412</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-20</td>\n",
       "      <td>3</td>\n",
       "      <td>0 days 00:01:31.567000</td>\n",
       "      <td>0 days 00:01:30.787000</td>\n",
       "      <td>0 days 00:01:30.687000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1039</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>57</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Finished</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>HAM</td>\n",
       "      <td>...</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>57</td>\n",
       "      <td>5.412</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-20</td>\n",
       "      <td>5</td>\n",
       "      <td>0 days 00:01:32.285000</td>\n",
       "      <td>0 days 00:01:31.048000</td>\n",
       "      <td>0 days 00:01:31.238000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1040</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>57</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Finished</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>RUS</td>\n",
       "      <td>...</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>57</td>\n",
       "      <td>5.412</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-20</td>\n",
       "      <td>9</td>\n",
       "      <td>0 days 00:01:32.269000</td>\n",
       "      <td>0 days 00:01:31.252000</td>\n",
       "      <td>0 days 00:01:32.216000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1041</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Finished</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>MAG</td>\n",
       "      <td>...</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>57</td>\n",
       "      <td>5.412</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-20</td>\n",
       "      <td>7</td>\n",
       "      <td>0 days 00:01:31.955000</td>\n",
       "      <td>0 days 00:01:31.461000</td>\n",
       "      <td>0 days 00:01:31.808000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   result_id  position  grid_position  points  laps_completed  \\\n",
       "0       1037       1.0            1.0    26.0              57   \n",
       "1       1038       2.0            3.0    18.0              57   \n",
       "2       1039       3.0            5.0    15.0              57   \n",
       "3       1040       4.0            9.0    12.0              57   \n",
       "4       1041       5.0            7.0    10.0              57   \n",
       "\n",
       "   fastest_lap_rank    status  is_sprint  driver_id driver_code  ...  country  \\\n",
       "0               1.0  Finished      False          4         LEC  ...  Bahrain   \n",
       "1               3.0  Finished      False          3         SAI  ...  Bahrain   \n",
       "2               5.0  Finished      False          7         HAM  ...  Bahrain   \n",
       "3               6.0  Finished      False          5         RUS  ...  Bahrain   \n",
       "4               8.0  Finished      False         12         MAG  ...  Bahrain   \n",
       "\n",
       "  circuit_type total_laps  circuit_length  has_sprint   race_date  \\\n",
       "0    Permanent         57           5.412           0  2022-03-20   \n",
       "1    Permanent         57           5.412           0  2022-03-20   \n",
       "2    Permanent         57           5.412           0  2022-03-20   \n",
       "3    Permanent         57           5.412           0  2022-03-20   \n",
       "4    Permanent         57           5.412           0  2022-03-20   \n",
       "\n",
       "   quali_position                 q1_time                 q2_time  \\\n",
       "0               1  0 days 00:01:31.471000  0 days 00:01:30.932000   \n",
       "1               3  0 days 00:01:31.567000  0 days 00:01:30.787000   \n",
       "2               5  0 days 00:01:32.285000  0 days 00:01:31.048000   \n",
       "3               9  0 days 00:01:32.269000  0 days 00:01:31.252000   \n",
       "4               7  0 days 00:01:31.955000  0 days 00:01:31.461000   \n",
       "\n",
       "                  q3_time  \n",
       "0  0 days 00:01:30.558000  \n",
       "1  0 days 00:01:30.687000  \n",
       "2  0 days 00:01:31.238000  \n",
       "3  0 days 00:01:32.216000  \n",
       "4  0 days 00:01:31.808000  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ba158de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1699 entries, 0 to 1698\n",
      "Data columns (total 31 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   result_id             1699 non-null   int64  \n",
      " 1   position              1697 non-null   float64\n",
      " 2   grid_position         1659 non-null   float64\n",
      " 3   points                1699 non-null   float64\n",
      " 4   laps_completed        1699 non-null   int64  \n",
      " 5   fastest_lap_rank      1654 non-null   float64\n",
      " 6   status                1699 non-null   object \n",
      " 7   is_sprint             1699 non-null   bool   \n",
      " 8   driver_id             1699 non-null   int64  \n",
      " 9   driver_code           1699 non-null   object \n",
      " 10  driver_number         1699 non-null   int64  \n",
      " 11  driver_nationality    0 non-null      object \n",
      " 12  driver_age            0 non-null      object \n",
      " 13  driver_championships  1699 non-null   int64  \n",
      " 14  team_id               1699 non-null   int64  \n",
      " 15  team_name             1699 non-null   object \n",
      " 16  race_id               1699 non-null   int64  \n",
      " 17  season                1699 non-null   int64  \n",
      " 18  round_number          1699 non-null   int64  \n",
      " 19  race_name             1699 non-null   object \n",
      " 20  circuit_location      1699 non-null   object \n",
      " 21  country               1699 non-null   object \n",
      " 22  circuit_type          1699 non-null   object \n",
      " 23  total_laps            1699 non-null   int64  \n",
      " 24  circuit_length        1699 non-null   float64\n",
      " 25  has_sprint            1699 non-null   int64  \n",
      " 26  race_date             1699 non-null   object \n",
      " 27  quali_position        1699 non-null   int64  \n",
      " 28  q1_time               1699 non-null   object \n",
      " 29  q2_time               1699 non-null   object \n",
      " 30  q3_time               1699 non-null   object \n",
      "dtypes: bool(1), float64(5), int64(12), object(13)\n",
      "memory usage: 400.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ee8d9c",
   "metadata": {},
   "source": [
    "## Temporal Weighting : \n",
    "- Give recent races higher weight using exponential decay \n",
    "- Makes model focus on recent driver/team performance\n",
    "<pre>\n",
    "1) First calculate days since last race\n",
    "2) Exponential delay function to get temporal weights:\n",
    "        Half life of 180 days\n",
    "        i.e. A race of 0 days ago will have weight of 1\n",
    "             A race of 180 days ago will have weight of 0.5  \n",
    "3) Calculate season weights as recent season performances are more important\n",
    "        Recent 2025 season has weight 1\n",
    "        2024 season has weight 0.7\n",
    "        Rest all (if any) have weight 0.5\n",
    "4) Multiply temporal and season weights to get final sample weights                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0906acda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season weights applied:\n",
      "season_weight\n",
      "0.7    460\n",
      "0.5    435\n",
      "0.3    419\n",
      "1.0    385\n",
      "Name: count, dtype: int64\n",
      "      season  race_date  temporal_weight  season_weight  sample_weight\n",
      "72      2022 2022-04-24         0.007206            0.3       0.002162\n",
      "222     2022 2022-07-24         0.010230            0.3       0.003069\n",
      "1244    2024 2024-11-03         0.252905            0.7       0.177033\n",
      "551     2023 2023-06-04         0.034408            0.5       0.017204\n",
      "389     2022 2022-11-13         0.015746            0.3       0.004724\n",
      "104     2022 2022-05-22         0.008026            0.3       0.002408\n",
      "985     2024 2024-05-19         0.132433            0.7       0.092703\n",
      "44      2022 2022-04-10         0.006827            0.3       0.002048\n",
      "312     2022 2022-10-02         0.013394            0.3       0.004018\n",
      "982     2024 2024-05-19         0.132433            0.7       0.092703\n"
     ]
    }
   ],
   "source": [
    "df['race_date'] = pd.to_datetime(df['race_date'])\n",
    "most_recent_race = df['race_date'].max()\n",
    "df['days_since_race'] = (most_recent_race - df['race_date']).dt.days\n",
    "\n",
    "# 1. Exponential decay based on time (Half-life of 180 days)\n",
    "half_life = 180\n",
    "df['temporal_weight'] = np.exp(-np.log(2) * df['days_since_race'] / half_life)\n",
    "\n",
    "# 2. UPDATED Season-specific weights\n",
    "# We have data from 2022, 2023, 2024, and 2025.\n",
    "season_weight_map = {\n",
    "    2025: 1.0,  # Most important (Test set)\n",
    "    2024: 0.7,  # Very important (Recent)\n",
    "    2023: 0.5,  # Relevant\n",
    "    2022: 0.3   # Less relevant (different car regulations)\n",
    "}\n",
    "df['season_weight'] = df['season'].apply(lambda x: season_weight_map.get(x, 0.2))\n",
    "print(\"Season weights applied:\")\n",
    "print(df['season_weight'].value_counts())\n",
    "\n",
    "# 3. Final sample weight\n",
    "df['sample_weight'] = df['temporal_weight'] * df['season_weight']\n",
    "\n",
    "print(df[['season','race_date','temporal_weight','season_weight','sample_weight']].sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7038ccce",
   "metadata": {},
   "source": [
    "### Qualifying feature Engineering:\n",
    "- Incorporates qualifying performance (Q1–Q3), grid penalties, and relative speed to pole.\n",
    "\n",
    "<pre>\n",
    "1) Clean data : If any driver is found having a mmissing quali position (happens if they crashed in q1/q2 or didnt set a time),\n",
    "                it is filled with their grid position.\n",
    "2) Grid penalty is calculated \n",
    "3) Normalize qualifying position.\n",
    "        Pole Position (P1) becomes 1/20 = 0.05 (the \"best\" score).\n",
    "        Last Place (P20) becomes 20/20 = 1.0 (the \"worst\" score).   \n",
    "4) Conver lap time strings to numerical format for calculation\n",
    "5) Calculate gap_to_pole to measure pure,relative pace against the fastest car                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb4f94c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Qualifying features created.\n"
     ]
    }
   ],
   "source": [
    "df['quali_position'].fillna(df['grid_position'], inplace=True)\n",
    "df['grid_penalty'] = df['grid_position'] - df['quali_position']\n",
    "df['quali_position_normalized'] = df['quali_position'] / 20 # Assuming ~20 cars\n",
    "\n",
    "laptime_pattern = re.compile(r'(\\d{2}):(\\d{2}):(\\d{2}\\.\\d+)')\n",
    "\n",
    "def parse_laptime_from_string(time_str):\n",
    "    if pd.isna(time_str):\n",
    "        return None\n",
    "    try:\n",
    "        match = laptime_pattern.search(str(time_str))\n",
    "        if match:\n",
    "            hours = int(match.group(1))\n",
    "            minutes = int(match.group(2))\n",
    "            seconds = float(match.group(3))\n",
    "            return (hours * 3600) + (minutes * 60) + seconds\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['q3_seconds'] = df['q3_time'].apply(parse_laptime_from_string)\n",
    "df['q3_gap_to_pole'] = df.groupby('race_id')['q3_seconds'].transform(\n",
    "    lambda x: x - x.min() if x.notna().sum() > 0 else np.nan\n",
    ")\n",
    "print(\"✅ Qualifying features created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dafdb8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   quali_position  grid_position  grid_penalty                 q3_time  \\\n",
      "0               1            1.0           0.0  0 days 00:01:30.558000   \n",
      "1               3            3.0           0.0  0 days 00:01:30.687000   \n",
      "2               5            5.0           0.0  0 days 00:01:31.238000   \n",
      "3               9            9.0           0.0  0 days 00:01:32.216000   \n",
      "4               7            7.0           0.0  0 days 00:01:31.808000   \n",
      "\n",
      "   q3_seconds  q3_gap_to_pole  \n",
      "0      90.558           0.000  \n",
      "1      90.687           0.129  \n",
      "2      91.238           0.680  \n",
      "3      92.216           1.658  \n",
      "4      91.808           1.250  \n"
     ]
    }
   ],
   "source": [
    "print(df[['quali_position','grid_position','grid_penalty','q3_time','q3_seconds','q3_gap_to_pole']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a074608",
   "metadata": {},
   "source": [
    "### Circuit Features\n",
    "<pre>\n",
    "1) Checks if street circuit or not\n",
    "    Why : Street circuits (like Monaco, Baku, or Singapore) are fundamentally different from permanent tracks (like Silverstone or Suzuka).\n",
    "          They are often bumpier, have lower grip, and punish mistakes with walls instead of gravel.\n",
    "          This leads to more safety cars, different setup priorities, and can favor certain \"specialist\" drivers.\n",
    "\n",
    "2) Fills any null circuit length values with median of length\n",
    "\n",
    "3) Checks if circuit is >5km.\n",
    "    Why : Instead of passing individual length for each track just long/nnt long helps model learn simpler rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68d70379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Circuit features created.\n"
     ]
    }
   ],
   "source": [
    "df['is_street_circuit'] = df['circuit_type'].fillna('').str.contains('Street', case=False).astype(int)\n",
    "df['circuit_length'].fillna(df['circuit_length'].median(), inplace=True)\n",
    "df['is_long_circuit'] = (df['circuit_length'] > 5.0).astype(int)\n",
    "df['has_sprint'] = df['has_sprint'].fillna(0).astype(int)\n",
    "print(\"✅ Circuit features created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d289862c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     circuit_location  is_street_circuit  is_long_circuit  has_sprint\n",
      "514             Miami                  1                1           0\n",
      "1214           Austin                  0                1           0\n",
      "1513        Spielberg                  0                0           0\n",
      "439            Jeddah                  1                1           0\n",
      "488              Baku                  1                1           0\n"
     ]
    }
   ],
   "source": [
    "print(df[['circuit_location','is_street_circuit','is_long_circuit','has_sprint']].sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92f829d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original missing positions: 2\n",
      "Missing positions after fill: 0\n",
      "✅ Target variable 'position' imputed successfully.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original missing positions: {df['position'].isnull().sum()}\")\n",
    "# Fill NaN in 'position' with 20 (last place)\n",
    "df['position'].fillna(20, inplace=True)\n",
    "print(f\"Missing positions after fill: {df['position'].isnull().sum()}\")\n",
    "print(\"✅ Target variable 'position' imputed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5ff2ee",
   "metadata": {},
   "source": [
    "### Advanced Historical Features\n",
    "\n",
    "1) Drivers:\n",
    "- Two helper columns(podium and dnf) to measure success and reliability\n",
    "- Weighted average finishing position over the last 5 races\n",
    "- Weighted average total points over the last 5 races\n",
    "- Weighted average podiums(eg : 0.6 = 60% podium rate) over last 5 races\n",
    "- Weighted DNF rate over last 5 matches\n",
    "- Recent form (A \"hotter,\" more sensitive version of average position, looking at only the last 3 races.)\n",
    "- Unweighted avg of quali position ober last 5 races\n",
    "\n",
    "2) Teams: (Gives \"car performance feature\")\n",
    "- Weighted avg finishing position\n",
    "- Weighted avg total points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33a32314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating driver weighted rolling stats...\n",
      "Calculating team weighted rolling stats...\n",
      "Merging stats back to main DataFrame...\n",
      "\n",
      "All leak-proof rolling features calculated and merged successfully.\n"
     ]
    }
   ],
   "source": [
    "def calculate_weighted_rolling_stats(group, window=5):\n",
    "    group = group.sort_values(['season', 'round_number'])\n",
    "    weights = group['sample_weight']\n",
    "\n",
    "    # --- ROBUST DNF FIX ---\n",
    "    dnf_statuses = [\n",
    "        'Accident', 'Collision', 'Engine', 'Gearbox', 'Retired', 'Disqualified',\n",
    "        'Chassis', 'Brakes', 'Clutch', 'Hydraulics', 'Electrical', 'Suspension',\n",
    "        'Puncture', 'Wheel', 'Overheating', 'Fuel system', 'Water pressure', 'Oil leak'\n",
    "    ]\n",
    "    group['dnf'] = group['status'].isin(dnf_statuses).astype(int)\n",
    "    # --- END FIX ---\n",
    "    \n",
    "    group['podium'] = (group['position'] <= 3).astype(int)\n",
    "\n",
    "    def weighted_avg(x):\n",
    "        return np.average(x, weights=weights[x.index])\n",
    "    \n",
    "    group['weighted_avg_position_5'] = group['position'].rolling(\n",
    "        window=window, min_periods=1\n",
    "    ).apply(weighted_avg, raw=False).shift(1)\n",
    "    \n",
    "    group['weighted_points_5'] = group['points'].rolling(\n",
    "        window=window, min_periods=1\n",
    "    ).apply(weighted_avg, raw=False).shift(1)\n",
    "    \n",
    "    group['weighted_podium_rate_5'] = group['podium'].rolling(\n",
    "        window=window, min_periods=1\n",
    "    ).apply(weighted_avg, raw=False).shift(1)\n",
    "    \n",
    "    group['weighted_dnf_rate_5'] = group['dnf'].rolling(\n",
    "        window=window, min_periods=1\n",
    "    ).apply(weighted_avg, raw=False).shift(1)\n",
    "    \n",
    "    # --- recent_form_3 BUG FIX ---\n",
    "    group['recent_form_3'] = group['position'].rolling(\n",
    "        window=3, min_periods=1  # Corrected to 3\n",
    "    ).apply(weighted_avg, raw=False).shift(1)\n",
    "    \n",
    "    if 'quali_position' in group.columns:\n",
    "        group['avg_quali_position_5'] = group['quali_position'].rolling(\n",
    "            window=window, min_periods=1\n",
    "        ).mean().shift(1)\n",
    "\n",
    "    new_cols = [\n",
    "        'weighted_avg_position_5', 'weighted_points_5', 'weighted_podium_rate_5',\n",
    "        'weighted_dnf_rate_5', 'recent_form_3', 'avg_quali_position_5'\n",
    "    ]\n",
    "    final_cols = [col for col in new_cols if col in group.columns]\n",
    "    return group[final_cols]\n",
    "\n",
    "\n",
    "def calculate_team_weighted_stats(group, window=5):\n",
    "    group = group.sort_values(['season', 'round_number'])\n",
    "    weights = group['sample_weight']\n",
    "\n",
    "    def weighted_avg(x):\n",
    "        return np.average(x, weights=weights[x.index])\n",
    "    \n",
    "    group['team_weighted_avg_position_5'] = group['position'].rolling(\n",
    "        window=window, min_periods=1\n",
    "    ).apply(weighted_avg, raw=False).shift(1)\n",
    "    \n",
    "    group['team_weighted_points_5'] = group['points'].rolling(\n",
    "        window=window, min_periods=1\n",
    "    ).apply(weighted_avg, raw=False).shift(1)\n",
    "    \n",
    "    return group[['team_weighted_avg_position_5', 'team_weighted_points_5']]\n",
    "\n",
    "# --- Use \"separate and join\" pattern to prevent bugs ---\n",
    "print(\"Calculating driver weighted rolling stats...\")\n",
    "driver_stats = df.groupby('driver_id', group_keys=False).apply(calculate_weighted_rolling_stats)\n",
    "\n",
    "print(\"Calculating team weighted rolling stats...\")\n",
    "team_stats = df.groupby('team_id', group_keys=False).apply(calculate_team_weighted_stats)\n",
    "\n",
    "print(\"Merging stats back to main DataFrame...\")\n",
    "df = df.join(driver_stats)\n",
    "df = df.join(team_stats)\n",
    "\n",
    "print(\"\\nAll leak-proof rolling features calculated and merged successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102823e1",
   "metadata": {},
   "source": [
    "### Head to head & teammate comparision\n",
    "<pre>\n",
    "It pairs each driver with their teammate in the same race,\n",
    "computes who beat whom and qualifying gap, then calculates a rolling teammate battle win rate (last 5 races) —\n",
    "shifted by one race to avoid data leakage — and merges these features back into the main DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d98cea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Robust teammate features created and merged.\n",
      "   Teammate data available: 1638 records\n"
     ]
    }
   ],
   "source": [
    "teammate_df = df[['race_id','team_id','driver_id','position','quali_position','points']].copy()\n",
    "teammate_df.columns = ['race_id','team_id','teammate_id','teammate_position','teammate_quali','teammate_points']\n",
    "\n",
    "teammate_battles_df = df[['race_id', 'team_id', 'driver_id', 'position', 'quali_position', 'season', 'round_number']]\n",
    "\n",
    "teammate_battles_df = teammate_battles_df.merge(\n",
    "    teammate_df,\n",
    "    on=['race_id', 'team_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "teammate_battles_df = teammate_battles_df[\n",
    "    teammate_battles_df['driver_id'] != teammate_battles_df['teammate_id']\n",
    "]\n",
    "\n",
    "teammate_battles_df['beat_teammate'] = (teammate_battles_df['position'] < teammate_battles_df['teammate_position']).astype(float)\n",
    "teammate_battles_df['quali_gap_to_teammate'] = teammate_battles_df['quali_position'] - teammate_battles_df['teammate_quali']\n",
    "\n",
    "teammate_battles_df = teammate_battles_df.sort_values(['driver_id', 'season', 'round_number'])\n",
    "teammate_battles_df['teammate_battle_rate_5'] = teammate_battles_df.groupby('driver_id')['beat_teammate'].transform(\n",
    "    lambda x: x.rolling(window=5, min_periods=1).mean().shift(1)\n",
    ")\n",
    "\n",
    "features_to_join = [\n",
    "    'race_id', \n",
    "    'driver_id', \n",
    "    'teammate_id', \n",
    "    'beat_teammate', \n",
    "    'quali_gap_to_teammate', \n",
    "    'teammate_battle_rate_5'\n",
    "]\n",
    "\n",
    "df = df.merge(\n",
    "    teammate_battles_df[features_to_join],\n",
    "    on=['race_id', 'driver_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"✅ Robust teammate features created and merged.\")\n",
    "print(f\"   Teammate data available: {df['teammate_id'].notna().sum()} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5816f63f",
   "metadata": {},
   "source": [
    "### Circuit Specific Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f80620f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Calculating leak-proof career fallback stats...\n",
      "   Calculating circuit-specific stats...\n",
      "   Filling missing circuit-specific stats...\n",
      "✅ Leak-proof circuit-specific features created\n"
     ]
    }
   ],
   "source": [
    "le_circuit = LabelEncoder()\n",
    "df['circuit_encoded'] = le_circuit.fit_transform(df['circuit_location'])\n",
    "df = df.sort_values(['season','round_number'])\n",
    "\n",
    "def weighted_expanding_average(group_data, val_col, w_col):\n",
    "    # --- BUG FIX: Use variables, not strings ---\n",
    "    vals = group_data[val_col]\n",
    "    weights = group_data[w_col]\n",
    "    # --- END FIX ---\n",
    "\n",
    "    expanding_sum = (vals*weights).expanding().sum()\n",
    "    expanding_w_sum = weights.expanding().sum()\n",
    "\n",
    "    return(expanding_sum/expanding_w_sum).shift(1)\n",
    "\n",
    "print(\"   Calculating leak-proof career fallback stats...\")\n",
    "df['career_weighted_pos'] = df.groupby('driver_id').apply(\n",
    "    lambda x: weighted_expanding_average(x, 'position', 'sample_weight')\n",
    ").reset_index(level=0, drop=True)\n",
    "\n",
    "df['career_weighted_points'] = df.groupby('driver_id').apply(\n",
    "    lambda x: weighted_expanding_average(x, 'points', 'sample_weight')\n",
    ").reset_index(level=0, drop=True)\n",
    "\n",
    "print(\"   Calculating circuit-specific stats...\")\n",
    "grouped = df.groupby(['circuit_encoded', 'driver_id'])\n",
    "\n",
    "df['driver_circuit_weighted_pos'] = grouped.apply(\n",
    "    lambda x: weighted_expanding_average(x, 'position', 'sample_weight')\n",
    ").reset_index(level=[0,1], drop=True)\n",
    "\n",
    "df['driver_circuit_weighted_points'] = grouped.apply(\n",
    "    lambda x: weighted_expanding_average(x, 'points', 'sample_weight')\n",
    ").reset_index(level=[0,1], drop=True)\n",
    "\n",
    "print(\"   Filling missing circuit-specific stats...\")\n",
    "df['driver_circuit_weighted_pos'].fillna(df['career_weighted_pos'], inplace=True)\n",
    "df['driver_circuit_weighted_points'].fillna(df['career_weighted_points'], inplace=True)\n",
    "\n",
    "# Fallback for a driver's first-ever race\n",
    "df['driver_circuit_weighted_pos'].fillna(df['position'].expanding().mean().shift(1), inplace=True)\n",
    "df['driver_circuit_weighted_points'].fillna(0, inplace=True)\n",
    "\n",
    "df = df.drop(columns=['career_weighted_pos', 'career_weighted_points'])\n",
    "\n",
    "print(f\"✅ Leak-proof circuit-specific features created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba713e6",
   "metadata": {},
   "source": [
    "### Championship position features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "478dbf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Calculating championship rank...\n",
      "   Calculating gap to leader...\n",
      "✅ Championship features created\n"
     ]
    }
   ],
   "source": [
    "df['championship_points_before_race'] = df.groupby(['season', 'driver_id'])['points'].transform(\n",
    "    lambda x: x.cumsum().shift(1)\n",
    ").fillna(0)\n",
    "\n",
    "print(\"   Calculating championship rank...\")\n",
    "df['championship_position_before_race'] = df.groupby(['season', 'round_number'])['championship_points_before_race'].rank(\n",
    "    method='min', ascending=False\n",
    ")\n",
    "\n",
    "print(\"   Calculating gap to leader...\")\n",
    "df['points_to_leader'] = df.groupby(['season', 'round_number'])['championship_points_before_race'].transform('max') - df['championship_points_before_race']\n",
    "\n",
    "print(f\"✅ Championship features created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83f660f",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea41775",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "198c5838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding high cardinality categorical features(circuit(done before), nationality)...\n",
      "One hot encoding low cardinality categorical features(driver,team)...\n",
      "   Saving encoders for pipeline...\n",
      "✅ Encoding complete. New dummy columns created.\n"
     ]
    }
   ],
   "source": [
    "print(\"Label Encoding high cardinality categorical features(circuit(done before), nationality)...\")\n",
    "\n",
    "le_nationality = LabelEncoder()\n",
    "df['nationality_encoded'] = le_nationality.fit_transform(df['driver_nationality'].fillna('Unknown'))\n",
    "\n",
    "print(\"One hot encoding low cardinality categorical features(driver,team)...\")\n",
    "df = pd.get_dummies(\n",
    "    df,\n",
    "    columns = ['driver_code','team_name'],\n",
    "    prefix = ['driver','team'],\n",
    "    dtype = int\n",
    ")\n",
    "\n",
    "print(\"   Saving encoders for pipeline...\")\n",
    "os.makedirs('ml/models/encoders_new', exist_ok=True)\n",
    "joblib.dump(le_nationality, 'ml/models/encoders_new/nationality_encoder.pkl')\n",
    "joblib.dump(le_circuit, 'ml/models/encoders_new/circuit_encoder.pkl')\n",
    "\n",
    "print(\"✅ Encoding complete. New dummy columns created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe486a8d",
   "metadata": {},
   "source": [
    "### Creating target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78760620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Target variables created.\n"
     ]
    }
   ],
   "source": [
    "df['win'] = (df['position'] == 1).astype(int)\n",
    "df['podium'] = (df['position'] <= 3).astype(int)\n",
    "df['top5'] = (df['position'] <= 5).astype(int)\n",
    "df['points_finish'] = (df['position'] <= 10).astype(int)\n",
    "print(\"✅ Target variables created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "527119a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1699 entries, 0 to 1698\n",
      "Columns: 104 entries, result_id to points_finish\n",
      "dtypes: bool(1), datetime64[ns](1), float64(29), int64(63), object(10)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd8bdb8",
   "metadata": {},
   "source": [
    "### Final feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa1c8d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling NaN values with intelligent defaults...\n",
      "   Imputing 20 other numeric columns with their training median...\n",
      "\n",
      "✅ All NaNs successfully imputed.\n",
      "\n",
      "✅ Feature set prepared:\n",
      "   Total Features: 74\n",
      "   Base Features: 24\n",
      "   One-Hot Driver Features: 36\n",
      "   One-Hot Team Features: 16\n"
     ]
    }
   ],
   "source": [
    "print(\"Filling NaN values with intelligent defaults...\")\n",
    "\n",
    "# --- 1. Special Imputation Rules ---\n",
    "# These NaNs have a specific meaning.\n",
    "\n",
    "# 'q3_gap_to_pole': NaN means \"didn't reach Q3\". Fill with a large penalty.\n",
    "df['q3_gap_to_pole'].fillna(99, inplace = True)\n",
    "# 'teammate_battle_rate_5': NaN (from .shift(1)) means no prior history. Fill with a neutral 0.5 (50/50).\n",
    "df['teammate_battle_rate_5'].fillna(0.5,inplace = True)\n",
    "# 'quali_gap_to_teammate': NaN means no teammate. Fill with a neutral 0.0 (no gap).\n",
    "df['quali_gap_to_teammate'].fillna(0.0,inplace = True)\n",
    "# 'avg_quali_position_5': NaN (from .shift(1)) means no prior history. Fill with a neutral \"mid-pack\" 10.0.\n",
    "df['avg_quali_position_5'].fillna(10.0,inplace=True)\n",
    "\n",
    "# Define the columns we just handled\n",
    "special_cols = ['q3_gap_to_pole', 'teammate_battle_rate_5', 'quali_gap_to_teammate', 'avg_quali_position_5']\n",
    "\n",
    "# --- 2. General Median Imputation (The Catch-All) ---\n",
    "# These are all other numeric features. NaNs here are from .shift(1) or missing DB data.\n",
    "# We will fill them with the median *of the training set* to prevent data leakage.\n",
    "\n",
    "# Define the *complete* list of base features first\n",
    "base_features = [\n",
    "    'grid_position',\n",
    "    'quali_position',\n",
    "    'driver_championships',\n",
    "    'circuit_encoded',    \n",
    "    'round_number',\n",
    "    \n",
    "    'grid_penalty',\n",
    "    'q3_gap_to_pole',\n",
    "    'avg_quali_position_5',\n",
    "    \n",
    "    'is_street_circuit',\n",
    "    'is_long_circuit',\n",
    "    'has_sprint',\n",
    "    \n",
    "    'weighted_avg_position_5',\n",
    "    'weighted_points_5',\n",
    "    'weighted_podium_rate_5',\n",
    "    'weighted_dnf_rate_5',\n",
    "    'recent_form_3',\n",
    "    \n",
    "    'team_weighted_avg_position_5', \n",
    "    'team_weighted_points_5',\n",
    "    \n",
    "    'quali_gap_to_teammate',\n",
    "    'teammate_battle_rate_5',\n",
    "    \n",
    "    'driver_circuit_weighted_pos',\n",
    "    'driver_circuit_weighted_points',\n",
    "    \n",
    "    'championship_position_before_race',\n",
    "    'points_to_leader',\n",
    "]\n",
    "\n",
    "# Get all numeric columns from base_features *except* the ones we just handled\n",
    "numeric_cols_to_fill = [\n",
    "    col for col in base_features \n",
    "    if col not in special_cols and df[col].dtype in ['float64', 'int64']\n",
    "]\n",
    "\n",
    "print(f\"   Imputing {len(numeric_cols_to_fill)} other numeric columns with their training median...\")\n",
    "\n",
    "for col in numeric_cols_to_fill:\n",
    "    # Calculate median *only* from the training data (seasons < 2025)\n",
    "    median_val = df[df['season'] < 2025][col].median()\n",
    "    \n",
    "    if pd.isna(median_val):\n",
    "        # Fallback if the whole column is NaN (unlikely, but safe)\n",
    "        median_val = 0\n",
    "        \n",
    "    # Fill NaNs in the *entire* DataFrame (train and test) with this value\n",
    "    df[col].fillna(median_val, inplace=True)\n",
    "\n",
    "# --- 3. Dynamically build the feature list ---\n",
    "\n",
    "# Re-filter base_features to only include ones that actually exist in the df\n",
    "base_features = [col for col in base_features if col in df.columns]\n",
    "\n",
    "ohe_driver_cols = [col for col in df.columns if col.startswith('driver_')]\n",
    "ohe_team_cols = [col for col in df.columns if col.startswith('team_')]\n",
    "\n",
    "feature_columns = base_features + ohe_driver_cols + ohe_team_cols \n",
    "feature_columns = [col for col in feature_columns if col not in ['driver_age', 'driver_nationality']]\n",
    "target_columns = ['win', 'podium', 'points_finish', 'top5', 'position']\n",
    "\n",
    "# --- 4. Final Check ---\n",
    "final_nan_count = df[feature_columns].isnull().sum().sum()\n",
    "if final_nan_count > 0:\n",
    "    print(f\"\\n⚠️ WARNING: {final_nan_count} NaNs still found in feature columns.\")\n",
    "    # Also print *which* columns still have NaNs\n",
    "    print(\"Columns with remaining NaNs:\")\n",
    "    print(df[feature_columns].isnull().sum()[df[feature_columns].isnull().sum() > 0])\n",
    "else:\n",
    "    print(\"\\n✅ All NaNs successfully imputed.\")\n",
    "\n",
    "print(f\"\\n✅ Feature set prepared:\")\n",
    "print(f\"   Total Features: {len(feature_columns)}\")\n",
    "print(f\"   Base Features: {len(base_features)}\")\n",
    "print(f\"   One-Hot Driver Features: {len(ohe_driver_cols)}\")\n",
    "print(f\"   One-Hot Team Features: {len(ohe_team_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c574dc",
   "metadata": {},
   "source": [
    "### Train/Test Split (With Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1135cbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Time-based split with temporal weighting:\n",
      "   Training set (Seasons 2022-2024): 1314 samples\n",
      "   - Avg weight: 0.051\n",
      "   - Weight range: 0.002 - 0.203\n",
      "   Test set (2025): 385 samples\n",
      "   - Avg weight: 0.655\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df['season'] < 2025].copy()\n",
    "test_df = df[df['season'] == 2025].copy()\n",
    "\n",
    "train_weights = train_df['sample_weight'].values\n",
    "test_weights = test_df['sample_weight'].values\n",
    "\n",
    "print(f\"✅ Time-based split with temporal weighting:\")\n",
    "print(f\"   Training set (Seasons 2022-2024): {len(train_df)} samples\")\n",
    "print(f\"   - Avg weight: {train_weights.mean():.3f}\")\n",
    "print(f\"   - Weight range: {train_weights.min():.3f} - {train_weights.max():.3f}\")\n",
    "print(f\"   Test set (2025): {len(test_df)} samples\")\n",
    "print(f\"   - Avg weight: {test_weights.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a085346",
   "metadata": {},
   "source": [
    "### Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be86d11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saving DataFrames to ml/data/processed/...\n",
      "   Saving weights to ml/data/processed/...\n",
      "   Saving metadata to ml/data/processed/...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/encoders_new/feature_columns_v3.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m     json.dump(metadata, f, indent=\u001b[32m2\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Save the feature list for the pipeline\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Feature list saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeatures_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✅ All data saved (V3)!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OMEN\\OneDrive\\Desktop\\f1-prediction-hub\\ml\\ml_venv\\Lib\\site-packages\\joblib\\numpy_pickle.py:599\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(value, filename, compress, protocol)\u001b[39m\n\u001b[32m    597\u001b[39m         NumpyPickler(f, protocol=protocol).dump(value)\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    600\u001b[39m         NumpyPickler(f, protocol=protocol).dump(value)\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../models/encoders_new/feature_columns_v3.joblib'"
     ]
    }
   ],
   "source": [
    "output_dir = \"ml/data/processed/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# We'll save these as v3 to show they are the new multi-season files\n",
    "data_path = os.path.join(output_dir, 'full_data_v3.parquet')\n",
    "train_path = os.path.join(output_dir, 'train_data_v3.parquet')\n",
    "test_path = os.path.join(output_dir, 'test_data_v3.parquet')\n",
    "train_weights_path = os.path.join(output_dir, 'train_weights_v3.npy')\n",
    "test_weights_path = os.path.join(output_dir, 'test_weights_v3.npy')\n",
    "metadata_path = os.path.join(output_dir, 'metadata_v3.json')\n",
    "features_path = \"../models/encoders_new/feature_columns_v3.joblib\"\n",
    "\n",
    "print(f\"   Saving DataFrames to {output_dir}...\")\n",
    "df.to_parquet(data_path, index=False, engine='fastparquet')\n",
    "train_df.to_parquet(train_path, index=False, engine='fastparquet')\n",
    "test_df.to_parquet(test_path, index=False, engine='fastparquet')\n",
    "\n",
    "print(f\"   Saving weights to {output_dir}...\")\n",
    "np.save(train_weights_path, train_weights)\n",
    "np.save(test_weights_path, test_weights)\n",
    "\n",
    "print(f\"   Saving metadata to {output_dir}...\")\n",
    "metadata = {\n",
    "    'feature_columns': feature_columns,\n",
    "    'target_columns': target_columns,\n",
    "    'train_size': len(train_df),\n",
    "    'test_size': len(test_df),\n",
    "    'train_seasons': [2022, 2023, 2024],\n",
    "    'test_season': 2025,\n",
    "    'temporal_weighting': {\n",
    "        '2022_weight': 0.3,\n",
    "        '2023_weight': 0.5,\n",
    "        '2024_weight': 0.7,\n",
    "        '2025_weight': 1.0,\n",
    "        'half_life_days': 180\n",
    "    }\n",
    "}\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "# Save the feature list for the pipeline\n",
    "joblib.dump(feature_columns, features_path)\n",
    "print(f\"   Feature list saved to {features_path}\")\n",
    "\n",
    "print(\"\\n✅ All data saved (V3)!\")\n",
    "print(\"\\n💡 NEXT STEP: Go to your modeling notebooks (LGBM, XGBoost) and update them to load `_v3` files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
